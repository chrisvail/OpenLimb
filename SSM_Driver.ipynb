{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1714293",
   "metadata": {},
   "source": [
    "# SSM Driver\n",
    "So what are we trying to do here? We're basically seeing if we can convince an ANN to predict the components of the SSM needed to match the measurements given as input. That way we can take 1D measurements and convert them into semi-realistic 3D data which would be nice. How we exactly are going to manage that? I honestly don't know. I guess the things we need are:\n",
    "1. **Dataloader** - a means of generating pairs of 3D models, their components and their measurements. That means I actually need to nail down how we define these measurements in the first place which isnt entirely obvious. I guess I just go with something that looks reasonable for now and we can refine exactly where the measurements are taken at a later date. Either way we're going to be giving it 4 circumfrential measures, 2 widths and a length and we'll see what comes out of it. \n",
    "2. **Loss function** - How exactly are we defining this loss - probably easiest by just using MSE between the 2 sets of measurements but it might be worth normalising them against the reference measure so that everything is of the same magnitude. Also probably worth creating a class or something that can just be passed the verts and output a set of measurements - this probably should be a `nn.Module` shouldn't it so it gets those nice properties? Idk maybe that doesnt matter too much?\n",
    "3. **Model** - This is probably the simplest part of the whole shabang. We can just start with a really simple dense network and see what happens. Maybe throw in some normalisation but really this should be as simple as possible.\n",
    "\n",
    "\n",
    "Something I havent really thought too much about is that I need to create these limbs based on my components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12031dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import igl\n",
    "import wandb\n",
    "\n",
    "from functools import partial\n",
    "import measure_limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bd34de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_verts = []\n",
    "# with open(\"verts.txt\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         if line[0] == \"#\":\n",
    "#             continue\n",
    "#         else:\n",
    "#             selected_verts.append([float(x) for x in line.strip().split(\", \")])\n",
    "\n",
    "# selected_verts = torch.tensor(selected_verts)\n",
    "\n",
    "# verts, face2vert = igl.read_triangle_mesh(\"./meshes/limb_00000.stl\")\n",
    "# verts = torch.tensor(verts[torch.load(\"./data_components/vert_mapping.pt\")])\n",
    "\n",
    "# verts.shape, selected_verts.shape\n",
    "\n",
    "# vert_idxs = torch.argmin(torch.linalg.norm(verts[None] - selected_verts[:, None], dim=-1), dim=-1)\n",
    "\n",
    "# # with open(\"test_verts.obj\", \"w\") as f:\n",
    "# #     for v in vert_idxs:\n",
    "# #         f.write(f\"v {verts[v][0]} {verts[v][1]} {verts[v][2]}\\n\") \n",
    "\n",
    "# torch.save(vert_idxs, \"data_components/selected_verts.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "777080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"eta_min\": 0.00001,\n",
    "    \"batch_size\": 256,\n",
    "    \"log\": False,\n",
    "    \"seed\": 42,\n",
    "    \"epochs\":500,\n",
    "}\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "if config[\"log\"]:\n",
    "    wandb.init(project=\"Open Limb SSM\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cfecb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Measurements(nn.Module):\n",
    "    def __init__(self, edge2vert, face2edge, details, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.edge2vert = edge2vert\n",
    "        self.face2edge = face2edge\n",
    "        self.details = details\n",
    "        self.measures = []\n",
    "\n",
    "        for detail in details:\n",
    "            match detail[\"type\"]:\n",
    "                case \"width\":\n",
    "                    measure = partial(measure_limbs.measure_width,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                        plane_direction=detail[\"plane_direction\"],\n",
    "                    )\n",
    "                case \"length\":\n",
    "                    measure = partial(measure_limbs.measure_length,\n",
    "                        v1=detail[\"v1\"], v2=detail[\"v2\"], direction=detail[\"direction\"]\n",
    "                    )\n",
    "                case \"circumference\":\n",
    "                    measure = partial(measure_limbs.measure_planar_circumference,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        face2edge=self.face2edge,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                    )\n",
    "            self.measures.append(measure)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        measures = [measure(x) for measure in self.measures]\n",
    "        if verbose:\n",
    "            for measure, detail in zip(measures, self.details):\n",
    "                print(f\"{detail['name'].ljust(20)}:\\t\\t{measure}\")\n",
    "        return torch.stack(measures, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3932456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LegMeasurementDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, measure, batch_size=64, path=\"./stls\", dtype=torch.float64, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.measure = measure\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.loaded_components = {}\n",
    "        self.raw_components = torch.load(\"./data_components/vert_components.pt\").to(dtype).to(device)\n",
    "        self.mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype).to(device)\n",
    "        self.face2vert = torch.load(\"./data_components/face2vert.pt\").to(device)\n",
    "        self.vert_mapping = torch.load(\"./data_components/vert_mapping.pt\").to(device)\n",
    "        self.component_transforms = torch.load(\"./data_components/scaled_component_transforms.pt\").to(dtype).to(device)\n",
    "        self.measurement_transforms = torch.load(\"./data_components/scaled_measurement_transforms.pt\").to(dtype).to(device)\n",
    "\n",
    "        # Remove all .npy files from the specified path\n",
    "        for file in os.listdir(self.path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                os.remove(os.path.join(self.path, file))\n",
    "\n",
    "        self.generate_data(0)\n",
    "        self.generate_data(self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100_000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index % self.batch_size == 0:\n",
    "            self.generate_data(index + self.batch_size*2)\n",
    "            ith_dataset = index // self.batch_size\n",
    "            if ith_dataset >= 2:\n",
    "                self.delete_data((ith_dataset - 2)*self.batch_size)\n",
    "\n",
    "        try:\n",
    "            components = self.loaded_components[(index // self.batch_size)*self.batch_size][\n",
    "                index % self.batch_size\n",
    "            ]\n",
    "        except KeyError:\n",
    "            self.generate_data(index)\n",
    "            components = self.loaded_components[(index // self.batch_size)*self.batch_size][\n",
    "                index % self.batch_size\n",
    "            ]\n",
    "\n",
    "        verts = self.get_verts(components)\n",
    "\n",
    "        measurements = self.get_measures(verts=verts, normalise=False).squeeze()\n",
    "\n",
    "        return measurements, components\n",
    "        # return verts, self.face2vert, measurements, components\n",
    "    \n",
    "\n",
    "    def get_verts(self, components):\n",
    "        if len(components.shape) == 1:\n",
    "            components, scale = components[:-1], components[-1:]\n",
    "        else:\n",
    "            components, scale = components[:,:-1], components[:,-1:]\n",
    "        \n",
    "        total = torch.sum(self.raw_components[None] * components[..., None], dim=1)\n",
    "        verts = self.mean_verts[None] + total.reshape((total.shape[0], self.mean_verts.shape[0], self.mean_verts.shape[1]))\n",
    "        verts = verts[:, self.vert_mapping]*scale[..., None]\n",
    "\n",
    "        return verts.squeeze()\n",
    "    \n",
    "    def get_measures(self, components=None, verts=None, verbose=False, normalise=False):\n",
    "        if components is not None:\n",
    "            verts = self.get_verts(components)\n",
    "\n",
    "        measurements = self.measure.forward(verts, verbose)\n",
    "\n",
    "        if normalise:\n",
    "            measurements = self.normalise_measures(measurements)\n",
    "\n",
    "        return measurements\n",
    "    \n",
    "    def normalise_measures(self, measurements):\n",
    "        return (measurements - self.measurement_transforms[:1]) / self.measurement_transforms[1:]\n",
    "\n",
    "    def generate_data(self, start):\n",
    "        cmd = [\n",
    "            \"./scripts/generate_limbs.sh\",\n",
    "            \"--num_limbs\",\n",
    "            f\"{self.batch_size}\",\n",
    "            \"--path\",\n",
    "            self.path,\n",
    "            \"--start\",\n",
    "            f\"{start}\",\n",
    "            \"--save_mesh\",\n",
    "            \"0\",\n",
    "            \"--scale\",\n",
    "            \"1\",\n",
    "            \"--seed\",\n",
    "            f\"{torch.randint(0, 100000, (1,))[0]}\"\n",
    "        ]\n",
    "        if os.name == \"nt\":  # Windows\n",
    "            cmd = [\"wsl\", \"-e\"] + cmd\n",
    "\n",
    "        subprocess.run(cmd, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                components = np.load(f\"{self.path}/components_{start:08d}.npy\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            else:\n",
    "                self.loaded_components[start] = torch.tensor(components, dtype=self.dtype, device=self.device)\n",
    "                break\n",
    "\n",
    "    def delete_data(self, start):\n",
    "        # for i in range(start, start + self.batch_size):\n",
    "            # try:\n",
    "            #     os.remove(f\"{self.path}/limb_{i:05d}.npy\")\n",
    "            # except FileNotFoundError:\n",
    "            #     pass\n",
    "\n",
    "        os.remove(f\"{self.path}/components_{start:08d}.npy\")\n",
    "        self.loaded_components.pop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5c2d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export_section\n",
    "dtype = torch.float64\n",
    "\n",
    "mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype)\n",
    "face2vert = torch.load(\"./data_components/face2vert.pt\")\n",
    "\n",
    "edge2vert, face2edge, edge2face = igl.edge_topology(\n",
    "    mean_verts.numpy(), face2vert.numpy()\n",
    ")\n",
    "\n",
    "edge2vert = torch.from_numpy(edge2vert)\n",
    "face2edge = torch.from_numpy(face2edge)\n",
    "edge2face = torch.from_numpy(edge2face)\n",
    "\n",
    "vert_idxs = torch.load(\"./data_components/selected_verts.pt\")\n",
    "\n",
    "# Order\n",
    "# Mid patella tendon\n",
    "# Distal tibia\n",
    "# Knee widest\n",
    "# Knee above? This one feels off\n",
    "# Over fib head\n",
    "# Fib head\n",
    "# Circ 3\n",
    "# Circ 4\n",
    "\n",
    "measurement_details = (\n",
    "    {\n",
    "        # Circ one\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[4],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[5],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 2\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[6],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 3\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[7],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 4\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"length\", \n",
    "        \"v1\": vert_idxs[0], \n",
    "        \"v2\": vert_idxs[1], \n",
    "        \"direction\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Length 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[2],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "        \"name\":\"Width 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[3],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "        \"name\":\"Width 2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "measure = Measurements(\n",
    "    edge2vert,\n",
    "    face2edge,\n",
    "    measurement_details,\n",
    ")\n",
    "\n",
    "#| end_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2fb246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, transforms, dtype, activation=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_transform = transforms\n",
    "        self.output_transform.requires_grad_(False)\n",
    "\n",
    "        self.layers = nn.ParameterList([\n",
    "            nn.Linear(input_dims, 256, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=256, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(256, 512, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=512, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(512, 1024, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=1024, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(1024, 128, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=128, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, output_dims, dtype=dtype)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x * self.output_transform[1:] + self.output_transform[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "41ac4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasurementLoss(nn.Module):\n",
    "    def __init__(self, measures: LegMeasurementDataset):\n",
    "        super().__init__()\n",
    "        self.measures = measures\n",
    "\n",
    "    def forward(self, components, true_components):\n",
    "        device = components.device\n",
    "        pred_measures = self.measures.get_measures(components.to(self.measures.device), verbose=False)\n",
    "        true_measures = self.measures.get_measures(true_components.to(self.measures.device), verbose=False)\n",
    "        # print(f\"{torch.isnan(components).sum()=}    {torch.isnan(measurements).sum()=}    {pred_measures.shape=}\")\n",
    "        return torch.mean((pred_measures - true_measures)**2 / (true_measures**2) + 1E-12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37c1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointwiseLoss(nn.Module):\n",
    "    def __init__(self, measures):\n",
    "        super().__init__()\n",
    "        self.measures = measures\n",
    "\n",
    "    def forward(self, pred_components, true_components):\n",
    "        device = pred_components.device\n",
    "        pred_verts = self.measures.get_verts(pred_components.to(self.measures.device))\n",
    "        true_verts = self.measures.get_verts(true_components.to(self.measures.device))\n",
    "        return torch.mean((pred_verts - true_verts)**2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3352e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = LegMeasurementDataset(measure, batch_size=config[\"batch_size\"], dtype=dtype, device=\"cpu\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, config[\"batch_size\"], shuffle=False)\n",
    "# loss_func = nn.MSELoss().to(device)\n",
    "# loss_func = MeasurementLoss(dataset).to(device)\n",
    "loss_func = PointwiseLoss(dataset).to(device)\n",
    "component_loss = nn.MSELoss()\n",
    "\n",
    "# Add one for the scale factor \n",
    "component_transforms = torch.load(\"./data_components/scaled_component_transforms.pt\").to(dtype).to(device)\n",
    "model = Model(len(measurement_details), dataset.raw_components.shape[0] + 1, component_transforms, dtype).to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, config[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a88c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(331.7358, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(118.7557, dtype=torch.float64), 'measurement difference': tensor(0.1206, dtype=torch.float64), 'maximum measurement difference': tensor(0.9560, dtype=torch.float64), 'minimum difference': tensor(5.1713e-05, dtype=torch.float64)}\n",
      "0\n",
      "{'loss': tensor(244.0327, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(104.8347, dtype=torch.float64), 'measurement difference': tensor(0.0841, dtype=torch.float64), 'maximum measurement difference': tensor(1.3503, dtype=torch.float64), 'minimum difference': tensor(2.2641e-05, dtype=torch.float64)}\n",
      "1\n",
      "{'loss': tensor(830.5244, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(200.9148, dtype=torch.float64), 'measurement difference': tensor(0.1300, dtype=torch.float64), 'maximum measurement difference': tensor(1.8014, dtype=torch.float64), 'minimum difference': tensor(0.0001, dtype=torch.float64)}\n",
      "2\n",
      "{'loss': tensor(282.5712, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(208.6217, dtype=torch.float64), 'measurement difference': tensor(0.0963, dtype=torch.float64), 'maximum measurement difference': tensor(0.8693, dtype=torch.float64), 'minimum difference': tensor(0.0001, dtype=torch.float64)}\n",
      "3\n",
      "{'loss': tensor(174.0523, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(254.4041, dtype=torch.float64), 'measurement difference': tensor(0.0997, dtype=torch.float64), 'maximum measurement difference': tensor(0.5136, dtype=torch.float64), 'minimum difference': tensor(0.0002, dtype=torch.float64)}\n",
      "4\n",
      "{'loss': tensor(175.4958, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(316.0529, dtype=torch.float64), 'measurement difference': tensor(0.0950, dtype=torch.float64), 'maximum measurement difference': tensor(0.6185, dtype=torch.float64), 'minimum difference': tensor(1.9629e-05, dtype=torch.float64)}\n",
      "5\n",
      "{'loss': tensor(201.7671, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(297.8670, dtype=torch.float64), 'measurement difference': tensor(0.0845, dtype=torch.float64), 'maximum measurement difference': tensor(0.6988, dtype=torch.float64), 'minimum difference': tensor(5.0928e-05, dtype=torch.float64)}\n",
      "6\n",
      "{'loss': tensor(185.6449, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(313.3235, dtype=torch.float64), 'measurement difference': tensor(0.0669, dtype=torch.float64), 'maximum measurement difference': tensor(0.5034, dtype=torch.float64), 'minimum difference': tensor(5.9227e-05, dtype=torch.float64)}\n",
      "7\n",
      "{'loss': tensor(175.2043, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(277.8453, dtype=torch.float64), 'measurement difference': tensor(0.0578, dtype=torch.float64), 'maximum measurement difference': tensor(0.6032, dtype=torch.float64), 'minimum difference': tensor(0.0002, dtype=torch.float64)}\n",
      "8\n",
      "{'loss': tensor(140.2661, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(260.9995, dtype=torch.float64), 'measurement difference': tensor(0.0621, dtype=torch.float64), 'maximum measurement difference': tensor(0.4957, dtype=torch.float64), 'minimum difference': tensor(0.0003, dtype=torch.float64)}\n",
      "9\n",
      "{'loss': tensor(127.8507, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(217.4932, dtype=torch.float64), 'measurement difference': tensor(0.0658, dtype=torch.float64), 'maximum measurement difference': tensor(0.4480, dtype=torch.float64), 'minimum difference': tensor(5.0621e-05, dtype=torch.float64)}\n",
      "10\n",
      "{'loss': tensor(83.6411, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(202.3097, dtype=torch.float64), 'measurement difference': tensor(0.0744, dtype=torch.float64), 'maximum measurement difference': tensor(0.4656, dtype=torch.float64), 'minimum difference': tensor(0.0003, dtype=torch.float64)}\n",
      "11\n",
      "{'loss': tensor(80.0351, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(189.9775, dtype=torch.float64), 'measurement difference': tensor(0.0765, dtype=torch.float64), 'maximum measurement difference': tensor(0.5335, dtype=torch.float64), 'minimum difference': tensor(2.0179e-05, dtype=torch.float64)}\n",
      "12\n",
      "{'loss': tensor(75.8230, dtype=torch.float64, grad_fn=<MeanBackward0>), 'component loss': tensor(217.0057, dtype=torch.float64), 'measurement difference': tensor(0.0775, dtype=torch.float64), 'maximum measurement difference': tensor(0.4147, dtype=torch.float64), 'minimum difference': tensor(1.4486e-05, dtype=torch.float64)}\n",
      "13\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m decay = \u001b[32m0.9\u001b[39m\n\u001b[32m      4\u001b[39m best_loss = torch.inf\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\Documents\\University\\PhD\\OpenLimb\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\Documents\\University\\PhD\\OpenLimb\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chris\\Documents\\University\\PhD\\OpenLimb\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mLegMeasurementDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index % \u001b[38;5;28mself\u001b[39m.batch_size == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m         ith_dataset = index // \u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ith_dataset >= \u001b[32m2\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mLegMeasurementDataset.generate_data\u001b[39m\u001b[34m(self, start)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m\"\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# Windows\u001b[39;00m\n\u001b[32m     97\u001b[39m     cmd = [\u001b[33m\"\u001b[39m\u001b[33mwsl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-e\u001b[39m\u001b[33m\"\u001b[39m] + cmd\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\subprocess.py:552\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    554\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\subprocess.py:1211\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1208\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1213\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1214\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\subprocess.py:1630\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   1626\u001b[39m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[32m   1627\u001b[39m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[32m   1628\u001b[39m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[32m   1629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1630\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstdout_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1631\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout_thread.is_alive():\n\u001b[32m   1632\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m.args, orig_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\threading.py:1149\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1151\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\threading.py:1169\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1170\u001b[39m         lock.release()\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "alpha = 10\n",
    "decay = 0.9\n",
    "best_loss = torch.inf\n",
    "for measures, components in dataloader:\n",
    "    measures = measures.to(device)\n",
    "    components = components.to(device)\n",
    "    \n",
    "    preds = model(measures)\n",
    "    loss = loss_func(preds, components)\n",
    "    # loss = loss_func(preds, components)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_measures = dataset.get_measures(preds.to(\"cpu\"), None)\n",
    "        measures = measures.to(\"cpu\")\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(components)\n",
    "            print(preds)\n",
    "            break\n",
    "\n",
    "        if config[\"log\"]:\n",
    "            wandb.log({\n",
    "                \"loss\": loss,\n",
    "                \"component loss\":  component_loss(preds, components),\n",
    "                \"measurement difference\": torch.mean((pred_measures - measures).abs() / measures),\n",
    "                \"maximum measurement difference\": torch.max((pred_measures - measures).abs() / measures),\n",
    "                \"minimum difference\": torch.min((pred_measures - measures).abs() / measures),\n",
    "                \"scale\":torch.mean(preds[:,-1]),\n",
    "                \"scale min\":torch.min(preds[:,-1]),\n",
    "                \"scale max\":torch.max(preds[:,-1]),\n",
    "                \"scale std\":torch.std(preds[:,-1]),\n",
    "            })\n",
    "        else: \n",
    "            print({\n",
    "                \"loss\": loss,\n",
    "                \"component loss\":  component_loss(preds, components),\n",
    "                \"measurement difference\": torch.mean((pred_measures - measures).abs() / measures),\n",
    "                \"maximum measurement difference\": torch.max((pred_measures - measures).abs() / measures),\n",
    "                \"minimum difference\": torch.min((pred_measures - measures).abs() / measures) \n",
    "            })\n",
    "            \n",
    "        if loss < best_loss:\n",
    "            torch.save(model, \"models/best.pt\")\n",
    "            best_loss = loss\n",
    "    alpha *= decay\n",
    "    if i > config[\"epochs\"]:\n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    \n",
    "    scheduler.step()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wsl', '-e', './scripts/generate_limbs.sh', '--num_limbs', '16', '--path', './stls', '--start', '32', '--save_mesh', '0', '--scale', '1', '--seed', '21302']\n",
      "true_verts.shape=torch.Size([16, 7732, 3])    preds.shape=torch.Size([16, 11])\n",
      "torch.any(pred_measures < 0, dim=0)=tensor([False, False, False, False, False, False, False])\n",
      "['circumference', 'circumference', 'circumference', 'circumference', 'length', 'width', 'width']\n",
      "pv.shape=torch.Size([7732, 3])    tv.shape=torch.Size([7732, 3])\n",
      "pv.shape=torch.Size([7732, 3])    tv.shape=torch.Size([7732, 3])\n",
      "pv.shape=torch.Size([7732, 3])    tv.shape=torch.Size([7732, 3])\n",
      "pv.shape=torch.Size([7732, 3])    tv.shape=torch.Size([7732, 3])\n",
      "pv.shape=torch.Size([7732, 3])    tv.shape=torch.Size([7732, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"models/best.pt\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, config[\"batch_size\"], shuffle=False)\n",
    "model.eval()\n",
    "\n",
    "for measures, components in dataloader:\n",
    "    with torch.no_grad():\n",
    "        preds = model(measures)\n",
    "        # Get predicted and true vertices\n",
    "        pred_verts = dataset.get_verts(preds)\n",
    "        true_verts = dataset.get_verts(components)\n",
    "\n",
    "        pred_measures = dataset.get_measures(components)\n",
    "\n",
    "        print(f\"{true_verts.shape=}    {preds.shape=}\")\n",
    "        print(f\"{torch.any(pred_measures < 0, dim=0)=}\")\n",
    "        print(f\"{[x['type'] for x in measurement_details]}\")\n",
    "\n",
    "        for i, (pv, tv) in enumerate(zip(pred_verts, true_verts[:5])):\n",
    "            print(f\"{pv.shape=}    {tv.shape=}\")\n",
    "            # Save predicted mesh\n",
    "            with open(f\"meshes/predicted_{i:04d}.obj\", \"w\") as f:\n",
    "                for v in pv:\n",
    "                    f.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n",
    "                for face in dataset.face2vert:\n",
    "                    f.write(f\"f {face[0]+1} {face[1]+1} {face[2]+1}\\n\")\n",
    "\n",
    "            # Save true mesh\n",
    "            with open(f\"meshes/true_{i:04d}.obj\", \"w\") as f:\n",
    "                for v in tv:\n",
    "                    f.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n",
    "                for face in dataset.face2vert:\n",
    "                    f.write(f\"f {face[0]+1} {face[1]+1} {face[2]+1}\\n\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a06c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_exporter import export_notebook\n",
    "export_notebook(\"SSM_Driver.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenLimb (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

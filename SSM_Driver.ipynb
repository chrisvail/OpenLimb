{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1714293",
   "metadata": {},
   "source": [
    "# SSM Driver\n",
    "So what are we trying to do here? We're basically seeing if we can convince an ANN to predict the components of the SSM needed to match the measurements given as input. That way we can take 1D measurements and convert them into semi-realistic 3D data which would be nice. How we exactly are going to manage that? I honestly don't know. I guess the things we need are:\n",
    "1. **Dataloader** - a means of generating pairs of 3D models, their components and their measurements. That means I actually need to nail down how we define these measurements in the first place which isnt entirely obvious. I guess I just go with something that looks reasonable for now and we can refine exactly where the measurements are taken at a later date. Either way we're going to be giving it 4 circumfrential measures, 2 widths and a length and we'll see what comes out of it. \n",
    "2. **Loss function** - How exactly are we defining this loss - probably easiest by just using MSE between the 2 sets of measurements but it might be worth normalising them against the reference measure so that everything is of the same magnitude. Also probably worth creating a class or something that can just be passed the verts and output a set of measurements - this probably should be a `nn.Module` shouldn't it so it gets those nice properties? Idk maybe that doesnt matter too much?\n",
    "3. **Model** - This is probably the simplest part of the whole shabang. We can just start with a really simple dense network and see what happens. Maybe throw in some normalisation but really this should be as simple as possible.\n",
    "\n",
    "\n",
    "Something I havent really thought too much about is that I need to create these limbs based on my components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12031dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import igl\n",
    "import wandb\n",
    "\n",
    "from functools import partial\n",
    "import measure_limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"eta_min\": 0.00001,\n",
    "    \"batch_size\": 64,\n",
    "    \"log\": False,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "if config[\"log\"]:\n",
    "    wandb.init(project=\"PointNet++ - FaceScanData\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfecb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measurements(nn.Module):\n",
    "    def __init__(self, edge2vert, face2edge, details, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.edge2vert = edge2vert\n",
    "        self.face2edge = face2edge\n",
    "        self.details = details\n",
    "        self.measures = []\n",
    "\n",
    "        for detail in details:\n",
    "            match detail[\"type\"]:\n",
    "                case \"width\":\n",
    "                    measure = partial(measure_limbs.measure_width,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                        plane_direction=detail[\"plane_direction\"],\n",
    "                    )\n",
    "                case \"length\":\n",
    "                    measure = partial(measure_limbs.measure_length,\n",
    "                        v1=detail[\"v1\"], v2=detail[\"v2\"], direction=detail[\"direction\"]\n",
    "                    )\n",
    "                case \"circumference\":\n",
    "                    measure = partial(measure_limbs.measure_planar_circumference,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        face2edge=self.face2edge,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                    )\n",
    "            self.measures.append(measure)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.tensor([measure(x) for measure in self.measures])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3932456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegMeasurementDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, measure, batch_size=64, path=\"./stls\", dtype=torch.float64):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.measure = measure\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.loaded_components = {}\n",
    "        self.raw_components = torch.load(\"./data_components/vert_components.pt\").to(dtype)\n",
    "        self.mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype)\n",
    "        self.face2vert = torch.load(\"./data_components/face2vert.pt\")\n",
    "        self.vert_mapping = torch.load(\"./data_components/vert_mapping.pt\")\n",
    "\n",
    "        # Remove all .npy files from the specified path\n",
    "        for file in os.listdir(self.path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                os.remove(os.path.join(self.path, file))\n",
    "\n",
    "        self.generate_data(0)\n",
    "        self.generate_data(self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100_000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index % self.batch_size == 0:\n",
    "            self.generate_data(index + self.batch_size*2)\n",
    "            ith_dataset = index // self.batch_size\n",
    "            if ith_dataset >= 2:\n",
    "                self.delete_data((ith_dataset - 2)*self.batch_size)\n",
    "\n",
    "        components = self.loaded_components[(index // self.batch_size)*self.batch_size][\n",
    "            index % self.batch_size\n",
    "        ]\n",
    "\n",
    "        verts = self.mean_verts + torch.sum(self.raw_components * components[:, None], dim=0).reshape_as(self.mean_verts)\n",
    "        verts = verts[self.vert_mapping]\n",
    "\n",
    "        measurements = self.measure.forward(verts)\n",
    "\n",
    "        return measurements, components\n",
    "        # return verts, self.face2vert, measurements, components\n",
    "    \n",
    "\n",
    "    def get_verts(self, components):\n",
    "        verts = self.mean_verts + torch.sum(self.raw_components * components[:, None], dim=0).reshape_as(self.mean_verts)\n",
    "        verts = verts[self.vert_mapping]\n",
    "\n",
    "        return verts\n",
    "    \n",
    "    def get_measures(self, components=None, verts=None):\n",
    "        if components is not None:\n",
    "            verts = self.get_verts(components)\n",
    "        \n",
    "        return self.measure.forward(verts)\n",
    "\n",
    "    def generate_data(self, start):\n",
    "        cmd = [\n",
    "            \"./generate_limbs.sh\",\n",
    "            \"--num_limbs\",\n",
    "            f\"{self.batch_size}\",\n",
    "            \"--path\",\n",
    "            self.path,\n",
    "            \"--start\",\n",
    "            f\"{start}\",\n",
    "            \"--save_mesh\",\n",
    "            \"0\",\n",
    "        ]\n",
    "        if os.name == \"nt\":  # Windows\n",
    "            cmd = [\"wsl\", \"-e\"] + cmd\n",
    "\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                components = np.load(f\"{self.path}/components_{start:05d}.npy\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            else:\n",
    "                self.loaded_components[start] = torch.tensor(components, dtype=self.dtype)\n",
    "                break\n",
    "\n",
    "    def delete_data(self, start):\n",
    "        # for i in range(start, start + self.batch_size):\n",
    "            # try:\n",
    "            #     os.remove(f\"{self.path}/limb_{i:05d}.npy\")\n",
    "            # except FileNotFoundError:\n",
    "            #     pass\n",
    "\n",
    "        os.remove(f\"{self.path}/components_{start:05d}.npy\")\n",
    "        self.loaded_components.pop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5c2d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype)\n",
    "face2vert = torch.load(\"./data_components/face2vert.pt\")\n",
    "\n",
    "edge2vert, face2edge, edge2face = igl.edge_topology(\n",
    "    mean_verts.numpy(), face2vert.numpy()\n",
    ")\n",
    "\n",
    "measurement_details = (\n",
    "        {\n",
    "            \"type\": \"circumference\",\n",
    "            \"plane_point\": torch.tensor([[0, 0, 0]], dtype=dtype),\n",
    "            \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "measure = Measurements(\n",
    "    edge2vert,\n",
    "    face2edge,\n",
    "    measurement_details,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, activation=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ParameterList([\n",
    "            nn.Linear(input_dims, 256),\n",
    "            activation,\n",
    "            nn.Linear(256, 1024),\n",
    "            activation,\n",
    "            nn.Linear(1024, 1024),\n",
    "            activation,\n",
    "            nn.Linear(1024, 128),\n",
    "            activation,\n",
    "            nn.Linear(128, output_dims)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3352e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = LegMeasurementDataset(measure, batch_size=config[\"batch_size\"], dtype=dtype)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, config[\"batch_size\"], shuffle=False)\n",
    "loss_func = nn.MSELoss().to(device)\n",
    "\n",
    "\n",
    "model = Model(len(measurement_details), dataset.raw_components.shape[0]).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a88c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.5256, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(33.1391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(32.6755, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0870, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2366, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/app/working/GenerateRandomLimbs.py\", line 48, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/pyplot.py\", line 55, in <module>\n",
      "    import matplotlib.colorbar\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/colorbar.py\", line 19, in <module>\n",
      "    from matplotlib import _api, cbook, collections, cm, colors, contour, ticker\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/contour.py\", line 15, in <module>\n",
      "    from matplotlib.backend_bases import MouseButton\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/backend_bases.py\", line 49, in <module>\n",
      "    from matplotlib import (\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/text.py\", line 16, in <module>\n",
      "    from .font_manager import FontProperties\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/font_manager.py\", line 1588, in <module>\n",
      "    fontManager = _load_fontmanager()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/font_manager.py\", line 1582, in _load_fontmanager\n",
      "    fm = FontManager()\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/font_manager.py\", line 1048, in __init__\n",
      "    self.addfont(path)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/font_manager.py\", line 1082, in addfont\n",
      "    prop = ttfFontProperty(font)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/matplotlib/font_manager.py\", line 408, in ttfFontProperty\n",
      "    sfnt.get((*ms_key, font_subfamily), b'').decode('utf-16-be'),\n",
      "  File \"/usr/local/lib/python3.9/encodings/__init__.py\", line 98, in search_function\n",
      "    mod = __import__('encodings.' + modname, fromlist=_import_tail,\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 995, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1085, in _cache_bytecode\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1110, in set_data\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 186, in _write_atomic\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/OpenLimb/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/OpenLimb/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/OpenLimb/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mLegMeasurementDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index % \u001b[38;5;28mself\u001b[39m.batch_size == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         ith_dataset = index // \u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ith_dataset >= \u001b[32m2\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mLegMeasurementDataset.generate_data\u001b[39m\u001b[34m(self, start)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m\"\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# Windows\u001b[39;00m\n\u001b[32m     70\u001b[39m     cmd = [\u001b[33m\"\u001b[39m\u001b[33mwsl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-e\u001b[39m\u001b[33m\"\u001b[39m] + cmd\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/194/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/subprocess.py:552\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    554\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/194/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/subprocess.py:1203\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1201\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1202\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1203\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/194/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/subprocess.py:1266\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1264\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1271\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1272\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/194/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/subprocess.py:2061\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2059\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2060\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2061\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2063\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2064\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2065\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/snap/code/194/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/subprocess.py:2019\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2017\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2018\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2019\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2021\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2022\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2023\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2024\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i, (measures, components) in enumerate(dataloader):\n",
    "    measures = measures.to(device)\n",
    "    components = components.to(device)\n",
    "    \n",
    "    preds = model(measures)\n",
    "\n",
    "    loss = loss_func(preds, components)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if config[\"log\"]:\n",
    "        wandb.log({\n",
    "            \"loss\": loss\n",
    "        })\n",
    "    else: \n",
    "        print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenLimb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

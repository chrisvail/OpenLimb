{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1714293",
   "metadata": {},
   "source": [
    "# SSM Driver\n",
    "So what are we trying to do here? We're basically seeing if we can convince an ANN to predict the components of the SSM needed to match the measurements given as input. That way we can take 1D measurements and convert them into semi-realistic 3D data which would be nice. How we exactly are going to manage that? I honestly don't know. I guess the things we need are:\n",
    "1. **Dataloader** - a means of generating pairs of 3D models, their components and their measurements. That means I actually need to nail down how we define these measurements in the first place which isnt entirely obvious. I guess I just go with something that looks reasonable for now and we can refine exactly where the measurements are taken at a later date. Either way we're going to be giving it 4 circumfrential measures, 2 widths and a length and we'll see what comes out of it. \n",
    "2. **Loss function** - How exactly are we defining this loss - probably easiest by just using MSE between the 2 sets of measurements but it might be worth normalising them against the reference measure so that everything is of the same magnitude. Also probably worth creating a class or something that can just be passed the verts and output a set of measurements - this probably should be a `nn.Module` shouldn't it so it gets those nice properties? Idk maybe that doesnt matter too much?\n",
    "3. **Model** - This is probably the simplest part of the whole shabang. We can just start with a really simple dense network and see what happens. Maybe throw in some normalisation but really this should be as simple as possible.\n",
    "\n",
    "\n",
    "Something I havent really thought too much about is that I need to create these limbs based on my components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12031dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import igl\n",
    "import wandb\n",
    "\n",
    "from functools import partial\n",
    "import measure_limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd34de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_verts = []\n",
    "with open(\"verts.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            selected_verts.append([float(x) for x in line.strip().split(\", \")])\n",
    "\n",
    "selected_verts = torch.tensor(selected_verts)\n",
    "\n",
    "verts, face2vert = igl.read_triangle_mesh(\"limb_00000.stl\")\n",
    "verts = torch.tensor(verts[torch.load(\"./data_components/vert_mapping.pt\")])\n",
    "\n",
    "verts.shape, selected_verts.shape\n",
    "\n",
    "vert_idxs = torch.argmin(torch.linalg.norm(verts[None] - selected_verts[:, None], dim=-1), dim=-1)\n",
    "\n",
    "with open(\"test_verts.obj\", \"w\") as f:\n",
    "    for v in vert_idxs:\n",
    "        f.write(f\"v {verts[v][0]} {verts[v][1]} {verts[v][2]}\\n\") \n",
    "\n",
    "torch.save(vert_idxs, \"data_components/selected_verts.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777080c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>component loss</td><td>█▇▄▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▇▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>maximum measurement difference</td><td>▇▆▇▇█▇██▇▇▇▇▆▇▂▇▇█▇▅▅▆▆▅██▇█▆█▁█▇▇▃▇▃▆▆█</td></tr><tr><td>measurement difference</td><td>█▇▅▄▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>minimum difference</td><td>█▄▃▁▃▁▃▃▂▃▂▂▃▁▂▂▃▃▂▃▃▃▃▂▃▃▃▂▂▂▂▄▂▂▂▁▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>component loss</td><td>13840.52995</td></tr><tr><td>loss</td><td>0.99069</td></tr><tr><td>maximum measurement difference</td><td>0.99991</td></tr><tr><td>measurement difference</td><td>0.99529</td></tr><tr><td>minimum difference</td><td>0.98828</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-jazz-22</strong> at: <a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM/runs/pix82kgw' target=\"_blank\">https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM/runs/pix82kgw</a><br> View project at: <a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM' target=\"_blank\">https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250727_133319-pix82kgw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\chris\\Documents\\University\\PhD\\OpenLimb\\wandb\\run-20250727_174713-uffpl49o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM/runs/uffpl49o' target=\"_blank\">fine-morning-23</a></strong> to <a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM' target=\"_blank\">https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM/runs/uffpl49o' target=\"_blank\">https://wandb.ai/cvail-imperial-college-london/Open%20Limb%20SSM/runs/uffpl49o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "    \"lr\": 1e-2,\n",
    "    \"eta_min\": 0.00001,\n",
    "    \"batch_size\": 256,\n",
    "    \"log\": True,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "if config[\"log\"]:\n",
    "    wandb.init(project=\"Open Limb SSM\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfecb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measurements(nn.Module):\n",
    "    def __init__(self, edge2vert, face2edge, details, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.edge2vert = edge2vert\n",
    "        self.face2edge = face2edge\n",
    "        self.details = details\n",
    "        self.measures = []\n",
    "\n",
    "        for detail in details:\n",
    "            match detail[\"type\"]:\n",
    "                case \"width\":\n",
    "                    measure = partial(measure_limbs.measure_width,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                        plane_direction=detail[\"plane_direction\"],\n",
    "                    )\n",
    "                case \"length\":\n",
    "                    measure = partial(measure_limbs.measure_length,\n",
    "                        v1=detail[\"v1\"], v2=detail[\"v2\"], direction=detail[\"direction\"]\n",
    "                    )\n",
    "                case \"circumference\":\n",
    "                    measure = partial(measure_limbs.measure_planar_circumference,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        face2edge=self.face2edge,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                    )\n",
    "            self.measures.append(measure)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        measures = [measure(x) for measure in self.measures]\n",
    "        if verbose:\n",
    "            for measure, detail in zip(measures, self.details):\n",
    "                print(f\"{detail['name'].ljust(20)}:\\t\\t{measure}\")\n",
    "        return torch.stack(measures, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3932456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegMeasurementDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, measure, batch_size=64, path=\"./stls\", dtype=torch.float64, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.measure = measure\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.loaded_components = {}\n",
    "        self.raw_components = torch.load(\"./data_components/vert_components.pt\").to(dtype).to(device)\n",
    "        self.mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype).to(device)\n",
    "        self.face2vert = torch.load(\"./data_components/face2vert.pt\").to(device)\n",
    "        self.vert_mapping = torch.load(\"./data_components/vert_mapping.pt\").to(device)\n",
    "\n",
    "        # Remove all .npy files from the specified path\n",
    "        for file in os.listdir(self.path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                os.remove(os.path.join(self.path, file))\n",
    "\n",
    "        self.generate_data(0)\n",
    "        self.generate_data(self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100_000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index % self.batch_size == 0:\n",
    "            self.generate_data(index + self.batch_size*2)\n",
    "            ith_dataset = index // self.batch_size\n",
    "            if ith_dataset >= 2:\n",
    "                self.delete_data((ith_dataset - 2)*self.batch_size)\n",
    "\n",
    "        components = self.loaded_components[(index // self.batch_size)*self.batch_size][\n",
    "            index % self.batch_size\n",
    "        ]\n",
    "\n",
    "        verts = self.get_verts(components)\n",
    "\n",
    "        measurements = self.measure.forward(verts).squeeze()\n",
    "\n",
    "        return measurements, components\n",
    "        # return verts, self.face2vert, measurements, components\n",
    "    \n",
    "\n",
    "    def get_verts(self, components):\n",
    "        if len(components.shape) == 1:\n",
    "            components, scale = components[:-1], components[-1:]\n",
    "        else:\n",
    "            components, scale = components[:,:-1], components[:,-1:]\n",
    "        \n",
    "        total = torch.sum(self.raw_components[None] * components[..., None], dim=1)\n",
    "        verts = self.mean_verts[None] + total.reshape((total.shape[0], self.mean_verts.shape[0], self.mean_verts.shape[1]))\n",
    "        verts = verts[:, self.vert_mapping]*scale[..., None]\n",
    "\n",
    "        return verts.squeeze()\n",
    "    \n",
    "    def get_measures(self, components=None, verts=None, verbose=False):\n",
    "        if components is not None:\n",
    "            verts = self.get_verts(components)\n",
    "        \n",
    "        return self.measure.forward(verts, verbose)\n",
    "\n",
    "    def generate_data(self, start):\n",
    "        cmd = [\n",
    "            \"./generate_limbs.sh\",\n",
    "            \"--num_limbs\",\n",
    "            f\"{self.batch_size}\",\n",
    "            \"--path\",\n",
    "            self.path,\n",
    "            \"--start\",\n",
    "            f\"{start}\",\n",
    "            \"--save_mesh\",\n",
    "            \"0\",\n",
    "            \"--scale\",\n",
    "            \"1\"\n",
    "        ]\n",
    "        if os.name == \"nt\":  # Windows\n",
    "            cmd = [\"wsl\", \"-e\"] + cmd\n",
    "\n",
    "        subprocess.run(cmd, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                components = np.load(f\"{self.path}/components_{start:08d}.npy\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            else:\n",
    "                self.loaded_components[start] = torch.tensor(components, dtype=self.dtype, device=self.device)\n",
    "                break\n",
    "\n",
    "    def delete_data(self, start):\n",
    "        # for i in range(start, start + self.batch_size):\n",
    "            # try:\n",
    "            #     os.remove(f\"{self.path}/limb_{i:05d}.npy\")\n",
    "            # except FileNotFoundError:\n",
    "            #     pass\n",
    "\n",
    "        os.remove(f\"{self.path}/components_{start:08d}.npy\")\n",
    "        self.loaded_components.pop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c2d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64\n",
    "\n",
    "mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype)\n",
    "face2vert = torch.load(\"./data_components/face2vert.pt\")\n",
    "\n",
    "edge2vert, face2edge, edge2face = igl.edge_topology(\n",
    "    mean_verts.numpy(), face2vert.numpy()\n",
    ")\n",
    "\n",
    "edge2vert = torch.from_numpy(edge2vert)\n",
    "face2edge = torch.from_numpy(face2edge)\n",
    "edge2face = torch.from_numpy(edge2face)\n",
    "\n",
    "\n",
    "vert_idxs = torch.load(\"./data_components/selected_verts.pt\")\n",
    "\n",
    "# Order\n",
    "# Mid patella tendon\n",
    "# Distal tibia\n",
    "# Knee widest\n",
    "# Knee above? This one feels off\n",
    "# Over fib head\n",
    "# Fib head\n",
    "# Circ 3\n",
    "# Circ 4\n",
    "\n",
    "measurement_details = (\n",
    "    {\n",
    "        # Circ one\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[4],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[5],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 2\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[6],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 3\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[7],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Circumference 4\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"length\", \n",
    "        \"v1\": vert_idxs[0], \n",
    "        \"v2\": vert_idxs[1], \n",
    "        \"direction\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"name\":\"Length 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[2],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "        \"name\":\"Width 1\",\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[3],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "        \"name\":\"Width 2\",\n",
    "    },\n",
    ")\n",
    "\n",
    "measure = Measurements(\n",
    "    edge2vert,\n",
    "    face2edge,\n",
    "    measurement_details,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fb246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, dtype, activation=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ParameterList([\n",
    "            nn.BatchNorm1d(num_features=input_dims, dtype=dtype),\n",
    "            nn.Linear(input_dims, 256, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=256, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(256, 1024, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=1024, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(1024, 2048, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=2048, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Linear(2048, 128, dtype=dtype),\n",
    "            nn.BatchNorm1d(num_features=128, dtype=dtype),\n",
    "            activation,\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, output_dims, dtype=dtype)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41ac4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasurementLoss(nn.Module):\n",
    "    def __init__(self, measures: LegMeasurementDataset):\n",
    "        super().__init__()\n",
    "        self.measures = measures\n",
    "\n",
    "    def forward(self, components, true_components):\n",
    "        pred_measures = self.measures.get_measures(components, verbose=False)\n",
    "        true_measures = self.measures.get_measures(true_components, verbose=False)\n",
    "        # print(f\"{torch.isnan(components).sum()=}    {torch.isnan(measurements).sum()=}    {pred_measures.shape=}\")\n",
    "        return torch.mean((pred_measures - true_measures)**2 / (true_measures**2) + 1E-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c1b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointwiseLoss(nn.Module):\n",
    "    def __init__(self, measures):\n",
    "        super().__init__()\n",
    "        self.measures = measures\n",
    "\n",
    "    def forward(self, pred_components, true_components):\n",
    "        pred_verts = self.measures.get_verts(pred_components)\n",
    "        true_verts = self.measures.get_verts(true_components)\n",
    "        return torch.mean((pred_verts - true_verts)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3352e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = LegMeasurementDataset(measure, batch_size=config[\"batch_size\"], dtype=dtype, device=\"cpu\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, config[\"batch_size\"], shuffle=False)\n",
    "# loss_func = nn.MSELoss().to(device)\n",
    "loss_func = MeasurementLoss(dataset).to(device)\n",
    "# loss_func = PointwiseLoss(dataset).to(device)\n",
    "component_loss = nn.MSELoss()\n",
    "\n",
    "# Add one for the scale factor \n",
    "model = Model(len(measurement_details), dataset.raw_components.shape[0] + 1, dtype).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a88c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "alpha = 10\n",
    "decay = 0.9\n",
    "for measures, components in dataloader:\n",
    "    measures = measures.to(device)\n",
    "    components = components.to(device)\n",
    "    \n",
    "    preds = model(measures)\n",
    "\n",
    "    loss = loss_func(preds, components) + component_loss(preds, components)*alpha\n",
    "    # loss = loss_func(preds, components)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_measures = dataset.get_measures(preds.to(\"cpu\"), None)\n",
    "        measures = measures.to(\"cpu\")\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(components)\n",
    "            print(preds)\n",
    "            break\n",
    "\n",
    "        if config[\"log\"]:\n",
    "            wandb.log({\n",
    "                \"loss\": loss,\n",
    "                \"component loss\":  component_loss(preds, components),\n",
    "                \"measurement difference\": torch.mean((pred_measures - measures).abs() / measures),\n",
    "                \"maximum measurement difference\": torch.max((pred_measures - measures).abs() / measures),\n",
    "                \"minimum difference\": torch.min((pred_measures - measures).abs() / measures) \n",
    "            })\n",
    "        else: \n",
    "            print({\n",
    "                \"loss\": loss,\n",
    "                \"component loss\":  component_loss(preds, components),\n",
    "                \"measurement difference\": torch.mean((pred_measures - measures).abs() / measures),\n",
    "                \"maximum measurement difference\": torch.max((pred_measures - measures).abs() / measures),\n",
    "                \"minimum difference\": torch.min((pred_measures - measures).abs() / measures) \n",
    "            })\n",
    "            pass\n",
    "    alpha *= decay\n",
    "    if i > 200:\n",
    "        break\n",
    "    else:\n",
    "        print(i)\n",
    "    \n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccac3baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-18\n",
      "2023-09-06\n",
      "2023-09-12\n",
      "2023-09-14\n",
      "2023-09-25\n",
      "2023-09-29\n",
      "2023-10-19\n",
      "2023-10-21\n",
      "2023-10-22\n",
      "2023-10-24\n",
      "2023-10-25\n",
      "2023-10-27\n",
      "2023-10-28\n",
      "2023-10-29\n",
      "2023-10-30\n",
      "2023-10-31\n",
      "2023-11-02\n",
      "2023-11-03\n",
      "2023-11-04\n",
      "2023-11-05\n",
      "2023-11-10\n",
      "2023-11-17\n",
      "2023-11-30\n",
      "2023-12-11\n",
      "2023-12-13\n",
      "2023-12-15\n",
      "2023-12-16\n",
      "2023-12-19\n",
      "2023-12-20\n",
      "2023-12-22\n",
      "2023-12-25\n",
      "2024-01-22\n",
      "2024-01-30\n",
      "2024-03-22\n",
      "2024-04-18\n",
      "2024-04-19\n",
      "2024-04-24\n",
      "2024-04-26\n",
      "2024-04-29\n",
      "2024-05-12\n",
      "2024-06-04\n",
      "2024-06-06\n",
      "2024-06-19\n",
      "2024-07-20\n",
      "2024-09-19\n",
      "2024-10-07\n",
      "2024-10-11\n",
      "2024-11-04\n",
      "2025-01-22\n",
      "2025-01-27\n",
      "2025-01-31\n",
      "2025-02-04\n",
      "2025-02-15\n",
      "2025-03-02\n",
      "2025-06-04\n",
      "2025-06-07\n",
      "2025-06-13\n",
      "2025-07-02 Sentence Completion\n",
      "2025-07-05\n",
      "2025-07-06\n",
      "2025-07-07\n",
      "2025-07-08\n",
      "2025-07-09\n",
      "2025-07-10\n",
      "2025-07-11\n",
      "2025-07-14\n",
      "2025-07-15\n",
      "2025-07-16\n",
      "2025-07-17\n",
      "2025-07-18\n",
      "2025-07-19\n",
      "2025-07-20\n",
      "2025-07-21\n",
      "2025-07-22\n",
      "2025-07-23\n",
      "2025-07-24\n",
      "2025-07-25\n",
      "2025-07-26\n",
      "Journalling\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(r\"C:\\Users\\chris\\Documents\\Core\\Daily Notes\")\n",
    "\n",
    "files = sorted(path.glob(\"*\"))\n",
    "# output_path = \"./Journalling.md\"\n",
    "output_path = path / \"Journalling.md\"\n",
    "with open(output_path, \"w\") as outfile:\n",
    "    for file in files:\n",
    "        print(file.stem)\n",
    "        date_str = file.stem[:10]\n",
    "        if date_str >= \"2025-05-01\" and date_str != \"Journallin\":\n",
    "            outfile.write(f\"# {file.stem}\\n\")\n",
    "            with open(file, \"r\") as infile:\n",
    "                outfile.write(infile.read())\n",
    "            outfile.write(\"\\n\\n---\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenLimb (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

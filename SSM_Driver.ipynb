{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1714293",
   "metadata": {},
   "source": [
    "# SSM Driver\n",
    "So what are we trying to do here? We're basically seeing if we can convince an ANN to predict the components of the SSM needed to match the measurements given as input. That way we can take 1D measurements and convert them into semi-realistic 3D data which would be nice. How we exactly are going to manage that? I honestly don't know. I guess the things we need are:\n",
    "1. **Dataloader** - a means of generating pairs of 3D models, their components and their measurements. That means I actually need to nail down how we define these measurements in the first place which isnt entirely obvious. I guess I just go with something that looks reasonable for now and we can refine exactly where the measurements are taken at a later date. Either way we're going to be giving it 4 circumfrential measures, 2 widths and a length and we'll see what comes out of it. \n",
    "2. **Loss function** - How exactly are we defining this loss - probably easiest by just using MSE between the 2 sets of measurements but it might be worth normalising them against the reference measure so that everything is of the same magnitude. Also probably worth creating a class or something that can just be passed the verts and output a set of measurements - this probably should be a `nn.Module` shouldn't it so it gets those nice properties? Idk maybe that doesnt matter too much?\n",
    "3. **Model** - This is probably the simplest part of the whole shabang. We can just start with a really simple dense network and see what happens. Maybe throw in some normalisation but really this should be as simple as possible.\n",
    "\n",
    "\n",
    "Something I havent really thought too much about is that I need to create these limbs based on my components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12031dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import igl\n",
    "import wandb\n",
    "\n",
    "from functools import partial\n",
    "import measure_limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd34de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_verts = []\n",
    "with open(\"verts.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line[0] == \"#\":\n",
    "            continue\n",
    "        else:\n",
    "            selected_verts.append([float(x) for x in line.strip().split(\", \")])\n",
    "\n",
    "selected_verts = torch.tensor(selected_verts)\n",
    "\n",
    "verts, face2vert = igl.read_triangle_mesh(\"limb_00000.stl\")\n",
    "verts = torch.tensor(verts[torch.load(\"./data_components/vert_mapping.pt\")])\n",
    "\n",
    "verts.shape, selected_verts.shape\n",
    "\n",
    "vert_idxs = torch.argmin(torch.linalg.norm(verts[None] - selected_verts[:, None], dim=-1), dim=-1)\n",
    "\n",
    "with open(\"test_verts.obj\", \"w\") as f:\n",
    "    for v in vert_idxs:\n",
    "        f.write(f\"v {verts[v][0]} {verts[v][1]} {verts[v][2]}\\n\") \n",
    "\n",
    "torch.save(vert_idxs, \"data_components/selected_verts.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"eta_min\": 0.00001,\n",
    "    \"batch_size\": 8,\n",
    "    \"log\": False,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "\n",
    "if config[\"log\"]:\n",
    "    wandb.init(project=\"Open Limb SSM\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfecb568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measurements(nn.Module):\n",
    "    def __init__(self, edge2vert, face2edge, details, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.edge2vert = edge2vert\n",
    "        self.face2edge = face2edge\n",
    "        self.details = details\n",
    "        self.measures = []\n",
    "\n",
    "        for detail in details:\n",
    "            match detail[\"type\"]:\n",
    "                case \"width\":\n",
    "                    measure = partial(measure_limbs.measure_width,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                        plane_direction=detail[\"plane_direction\"],\n",
    "                    )\n",
    "                case \"length\":\n",
    "                    measure = partial(measure_limbs.measure_length,\n",
    "                        v1=detail[\"v1\"], v2=detail[\"v2\"], direction=detail[\"direction\"]\n",
    "                    )\n",
    "                case \"circumference\":\n",
    "                    measure = partial(measure_limbs.measure_planar_circumference,\n",
    "                        edge2vert=self.edge2vert,\n",
    "                        face2edge=self.face2edge,\n",
    "                        plane_point=detail[\"plane_point\"],\n",
    "                        plane_normal=detail[\"plane_normal\"],\n",
    "                    )\n",
    "            self.measures.append(measure)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.tensor([measure(x) for measure in self.measures])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3932456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegMeasurementDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, measure, batch_size=64, path=\"./stls\", dtype=torch.float64, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "        self.device = device\n",
    "        self.measure = measure\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.loaded_components = {}\n",
    "        self.raw_components = torch.load(\"./data_components/vert_components.pt\").to(dtype).to(device)\n",
    "        self.mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype).to(device)\n",
    "        self.face2vert = torch.load(\"./data_components/face2vert.pt\").to(device)\n",
    "        self.vert_mapping = torch.load(\"./data_components/vert_mapping.pt\").to(device)\n",
    "\n",
    "        # Remove all .npy files from the specified path\n",
    "        for file in os.listdir(self.path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                os.remove(os.path.join(self.path, file))\n",
    "\n",
    "        self.generate_data(0)\n",
    "        self.generate_data(self.batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100_000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index % self.batch_size == 0:\n",
    "            self.generate_data(index + self.batch_size*2)\n",
    "            ith_dataset = index // self.batch_size\n",
    "            if ith_dataset >= 2:\n",
    "                self.delete_data((ith_dataset - 2)*self.batch_size)\n",
    "\n",
    "        components = self.loaded_components[(index // self.batch_size)*self.batch_size][\n",
    "            index % self.batch_size\n",
    "        ]\n",
    "\n",
    "        verts = self.get_verts(components)\n",
    "\n",
    "        measurements = self.measure.forward(verts)\n",
    "\n",
    "        return measurements, components\n",
    "        # return verts, self.face2vert, measurements, components\n",
    "    \n",
    "\n",
    "    def get_verts(self, components):\n",
    "        sum = torch.sum(self.raw_components[None] * components[..., None], dim=1)\n",
    "        verts = self.mean_verts[None] + sum.reshape((sum.shape[0], self.mean_verts.shape[0], self.mean_verts.shape[1]))\n",
    "        verts = verts[:, self.vert_mapping]\n",
    "\n",
    "        return verts.squeeze()\n",
    "    \n",
    "    def get_measures(self, components=None, verts=None):\n",
    "        if components is not None:\n",
    "            verts = self.get_verts(components)\n",
    "        \n",
    "        return self.measure.forward(verts)\n",
    "\n",
    "    def generate_data(self, start):\n",
    "        cmd = [\n",
    "            \"./generate_limbs.sh\",\n",
    "            \"--num_limbs\",\n",
    "            f\"{self.batch_size}\",\n",
    "            \"--path\",\n",
    "            self.path,\n",
    "            \"--start\",\n",
    "            f\"{start}\",\n",
    "            \"--save_mesh\",\n",
    "            \"0\",\n",
    "        ]\n",
    "        if os.name == \"nt\":  # Windows\n",
    "            cmd = [\"wsl\", \"-e\"] + cmd\n",
    "\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                components = np.load(f\"{self.path}/components_{start:08d}.npy\")\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            else:\n",
    "                self.loaded_components[start] = torch.tensor(components, dtype=self.dtype, device=self.device)\n",
    "                break\n",
    "\n",
    "    def delete_data(self, start):\n",
    "        # for i in range(start, start + self.batch_size):\n",
    "            # try:\n",
    "            #     os.remove(f\"{self.path}/limb_{i:05d}.npy\")\n",
    "            # except FileNotFoundError:\n",
    "            #     pass\n",
    "\n",
    "        os.remove(f\"{self.path}/components_{start:08d}.npy\")\n",
    "        self.loaded_components.pop(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c2d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "mean_verts = torch.load(\"./data_components/mean_verts.pt\").to(dtype)\n",
    "face2vert = torch.load(\"./data_components/face2vert.pt\")\n",
    "\n",
    "edge2vert, face2edge, edge2face = igl.edge_topology(\n",
    "    mean_verts.numpy(), face2vert.numpy()\n",
    ")\n",
    "\n",
    "vert_idxs = torch.load(\"./data_components/selected_verts.pt\")\n",
    "\n",
    "# Order\n",
    "# Mid patella tendon\n",
    "# Distal tibia\n",
    "# Knee widest\n",
    "# Knee above? This one feels off\n",
    "# Over fib head\n",
    "# Fib head\n",
    "# Circ 3\n",
    "# Circ 4\n",
    "\n",
    "measurement_details = (\n",
    "    {\n",
    "        # Circ one\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[4],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[5],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[6],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"circumference\",\n",
    "        \"plane_point\": vert_idxs[7],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"length\", \n",
    "        \"v1\": vert_idxs[0], \n",
    "        \"v2\": vert_idxs[1], \n",
    "        \"direction\": torch.tensor([[0, 0, 1]], dtype=dtype)\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[2],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"width\",\n",
    "        \"plane_point\": vert_idxs[3],\n",
    "        \"plane_normal\": torch.tensor([[0, 0, 1]], dtype=dtype),\n",
    "        \"plane_direction\": torch.tensor([[1, 0, 0]], dtype=dtype),\n",
    "    },\n",
    ")\n",
    "\n",
    "measure = Measurements(\n",
    "    edge2vert,\n",
    "    face2edge,\n",
    "    measurement_details,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dims, output_dims, activation=nn.ReLU(inplace=True)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ParameterList([\n",
    "            nn.Linear(input_dims, 256),\n",
    "            activation,\n",
    "            nn.Linear(256, 1024),\n",
    "            activation,\n",
    "            nn.Linear(1024, 1024),\n",
    "            activation,\n",
    "            nn.Linear(1024, 128),\n",
    "            activation,\n",
    "            nn.Linear(128, output_dims)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3352e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = LegMeasurementDataset(measure, batch_size=config[\"batch_size\"], dtype=dtype, device=\"cpu\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, config[\"batch_size\"], shuffle=False)\n",
    "loss_func = nn.MSELoss().to(device)\n",
    "\n",
    "\n",
    "model = Model(len(measurement_details), dataset.raw_components.shape[0]).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a88c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([7732, 3])\n",
      "verts.shape=torch.Size([8, 7732, 3])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 421 is out of bounds for dimension 0 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m optimizer.zero_grad()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     measurements = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_measures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[33m\"\u001b[39m\u001b[33mlog\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     16\u001b[39m     wandb.log({\n\u001b[32m     17\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m: loss\n\u001b[32m     18\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mLegMeasurementDataset.get_measures\u001b[39m\u001b[34m(self, components, verts)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     54\u001b[39m     verts = \u001b[38;5;28mself\u001b[39m.get_verts(components)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeasure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mMeasurements.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor([\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m measure \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.measures])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/OpenLimb/measure_limbs.py:18\u001b[39m, in \u001b[36mmeasure_planar_circumference\u001b[39m\u001b[34m(verts, edge2vert, face2edge, plane_point, plane_normal)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mverts.shape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(plane_point, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(plane_point, torch.Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(plane_point.shape)):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     plane_point = \u001b[43mverts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplane_point\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(plane_normal, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[32m     21\u001b[39m     plane_normal = verts[plane_normal[\u001b[32m0\u001b[39m]] - verts[plane_normal[\u001b[32m1\u001b[39m]]\n",
      "\u001b[31mIndexError\u001b[39m: index 421 is out of bounds for dimension 0 with size 8"
     ]
    }
   ],
   "source": [
    "for i, (measures, components) in enumerate(dataloader):\n",
    "    measures = measures.to(device)\n",
    "    components = components.to(device)\n",
    "    \n",
    "    preds = model(measures)\n",
    "\n",
    "    loss = loss_func(preds, components)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        measurements = dataset.get_measures(preds.to(\"cpu\"), None)\n",
    "\n",
    "    if config[\"log\"]:\n",
    "        wandb.log({\n",
    "            \"loss\": loss\n",
    "        })\n",
    "    else: \n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac3baa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenLimb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
